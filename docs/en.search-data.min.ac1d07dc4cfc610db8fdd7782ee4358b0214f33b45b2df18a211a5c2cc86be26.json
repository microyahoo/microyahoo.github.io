[{"id":0,"href":"/posts/etcd_raft/","title":"etcd raft","section":"Blog","content":" etcd 代码分析可以参考：etcd 注解版 ，也欢迎大家交流讨论\nRaft message type #  Raft集群中节点之间的通信都是通过传递不同的Message来完成的，Message类型 有很多种，下面介绍部分：\n MsgHup   用于选举，对于follower或者candidate，其tick函数对应tickElection。如果follower或者candidate在选举超时时间都没有收到心跳信息，它将发送MsgHup到Step方法，其角色将变为candidate（对于follower节点）并发起新一轮选举。\n  MsgBeat   MsgApp是一个内部使用的类型，对于leader节点，其tick函数对应tickHeartbeat，周期性地向follower节点发送MsgHeartbeat消息。\n  MsgProp   MsgProp提议附加数据到log entries，而且它会重定向propose到leader节点。因此，send方法用hardState覆写了Message的term号。-\n 当MsgProp传递到leader的step方法，leader首先会调用appendEntry方法将entries附加到它的log，接着会调用bcastAppend方法发送entries到peers。 当MsgProp传递到candidate，则直接丢弃。 当传递到follower，MsgProp存储到follower的mailbox，即msgs，它保存了发送者的ID，随后通过rafthttp包转发到leader。    MsgApp   复制log entries。leader调用bcastAppend方法，其会调用bcastAppend方法发送即将要复制的MsgApp类型的logs。当MsgApp被传递到candidate的Step方法，candidate将会revert back to follower，表示存在有效的leader在发送MsgApp消息。candidate和follower会回复MsgAppResp消息。\n  MsgAppResp   用于响应log复制请求。当MsgApp发送到candidate和follower的Step方法，它们会调用handleAppendEntries方法，其会发送MsgAppResp到raft mailbox。\n  MsgVote   请求投票选举。当MsgHup传递到follower或candidate的Step方法，将会调用campaign方法去竞选自己成为leader， 一旦campaign方法被调用，节点将会变成candidate，然后发送MsgVote到peers去请求投票。\n 当消息传递到leader或candidate的Step方法，如果消息的term小于leader或candidate的term，则消息会被拒绝掉（MsgVoteResp将设置Reject为true），如果leader或candidate接收到term更大的MsgVote，他们将会revert back to follower。 当\u0026rsquo;MsgVote\u0026rsquo;被传递给follower时，只有当sender的last term大于MsgVote的term或sender的last term等于MsgVote的term但sender的最后提交索引大于或等于follower的时，它才会投票给sender。    MsgVoteResp   投票选举相应消息。当candidate收到MsgVoteResp，它会统计自己的票数，如果票数超过quorum，它将会变成leader，然后调用bcastAppend，如果candidate收到大多数的拒绝投票，则revert back to follower。\n  MsgPreVote和MsgPreVoteResp   两阶段选举协议，是一个可选配置项。当Config.PreVote设置为true时，预选举过程与常规选举过程类似，只是不会增加term，除非它在第一个阶段竞选赢得了大多数票。加入这个选项可以将节点分区导致的影响降至最低。\n  MsgSnap   请求应用快照消息。当一个节点刚变为leader，或者leader接收到MsgProp消息，然后调用bcastAppend方法，这个方法会调用sendAppend方法到每个follower节点。在sendAppend方法中，如果leader获取term或者entries失败，则leader将会发送MsgSnap类型消息来请求快照。\n  MsgSnapStatus   告知快照消息应用的结果。当follower节点拒绝MsgSnap消息，表明因为网络问题导致网络层不能正常发送snapshot到follower，从而导致快照请求失败，leader将follower的progress设置为probe。当MsgSnap没有被拒绝，表明快照被正常接收，leader将follower的progress设置为probe，同时开始log复制。\n  MsgHeartbeat   leader发送心跳信息。\n 当MsgHeartbeat消息发送到candidate，且消息的term大于candidate的term，则candidate将revert back to follower，同时会更新自己的提交索引号，然后发送消息到mailbox。 当MsgHeartbeat消息发送到follower的Step方法，如果消息的term大于follower的term，则follower会更新leaderID。    MsgHeartbeatResp   心跳响应消息。MsgHeartbeatResp传递到leader的Step方法，leader会知道哪些节点做了回复响应。只有当leader最后提交索引号大于follower的Match索引号时leader调用sendAppend方法。\n  MsgUnreachable   告知消息或请求不能被deliver，当MsgUnreachable传递到leader的Step方法，leader发现发送MsgUnreachable消息的follower节点不可达，这通常意味着MsgApp丢失了。如果此时follower的progress状态为replicate，则leader会将其重新设置回probe状态。\n  MsgCheckQuorum   如果开启CheckQuorum，则选举超时后会发送MsgCheckQuorum消息，leader节点判断其是否满足quorum，如果不满足则step down to follower节点。\n  MsgReadIndex     MsgReadIndexResp     MsgTransferLeader   对于MsgTransferLeader消息，follower节点会将其转发到leader节点，leader节点在收到MsgTransferLeader消息后会首先记录lead被转移者，然后判断转移目标的日志是否跟上了。\n 如果跟上了会向被转移者发送 MsgTimeoutNow 消息, 被转移者收到消息后会强制发起新一轮选举。 如果没有跟上则先进行日志同步，等leader收到同步日志的MsgAppResp消息后会判断其是否已跟上，步骤同上。    MsgTimeoutNow    Local message #   MsgHup MsgBeat MsgUnreachable MsgSnapStatus MsgCheckQuorum  Response message #   MsgAppResp MsgVoteResp MsgHeartbeatResp MsgUnreachable MsgPreVoteResp   Q \u0026amp; A #   发送如下类型的消息时需要设置term，其他类型的消息都不需要设置term。   pb.MsgVote pb.MsgVoteResp pb.MsgPreVote pb.MsgPreVoteResp  但是对于消息类型既不是MsgProp，又不是MsgReadIndex类型的，会为其加上raft.Term，具体实现参考raft/raft.go中的 send()方法。\nraft的tracker.ProgressTracker在什么地方赋值的？   初始化集群时，如果没有WAL，同时为新集群，同时指定了--initial-cluster参数，会将其解析为ServerConfig的InitialPeerURLsMap参数，然后初始化RaftCluster，并添加members。接着bootstrapRaftFromCluster方法会根据cluster的member ids生成peers。 Peer的信息如下：\n type Peer struct { ID uint64 Context []byte } type Member struct { ID types.ID `json:\u0026#34;id\u0026#34;` RaftAttributes Attributes }  peer中的Context为Member序列化后的信息，其中包括 ID, RaftAttributes, Attributes信息。接着raft/node.go会调用StartNode方法，里面的Bootstrap方法会根据peers生成相应的pb.ConfChange entries，然后调用applyConfChange方法，这里会更新raft.prs，返回最新的tracker.Config和tracker.ProgressMap信息。\n (dlv) p cfg.Voters go.etcd.io/etcd/raft/v3/quorum.JointConfig [ [ 9372538179322589801: {}, 10501334649042878790: {}, 18249187646912138824: {}, ], nil, ] (dlv) p prs go.etcd.io/etcd/raft/v3/tracker.ProgressMap [ 9372538179322589801: *{ Match: 0, Next: 3, State: StateProbe (0), PendingSnapshot: 0, RecentActive: true, ProbeSent: false, Inflights: *(*\u0026#34;go.etcd.io/etcd/raft/v3/tracker.Inflights\u0026#34;)(0xc00012f470), IsLearner: false,}, 10501334649042878790: *{ Match: 0, Next: 3, State: StateProbe (0), PendingSnapshot: 0, RecentActive: true, ProbeSent: false, Inflights: *(*\u0026#34;go.etcd.io/etcd/raft/v3/tracker.Inflights\u0026#34;)(0xc00012f620), IsLearner: false,}, 18249187646912138824: *{ Match: 0, Next: 3, State: StateProbe (0), PendingSnapshot: 0, RecentActive: true, ProbeSent: false, Inflights: *(*\u0026#34;go.etcd.io/etcd/raft/v3/tracker.Inflights\u0026#34;)(0xc00012f560), IsLearner: false,}, ] apply的时候什么条件触发快照？ unstable中的快照是什么时候赋值的？什么条件触发？   TODO\n 为什么raft.msgs读写时不需要加锁？   其实etcd里很多地方都是采用的单线程模式，比如apply也是。\n 对于 raftpb.Message中的MsgApp类型，其LogTerm，Index, Commit, Entries的含义？   LogTerm通常用于append raft logs到follower节点。\n例如：对于消息(type=MsgApp,index=100,logTerm=5)，表示leader从index=101开始 append entries，而index=100对应的Term值为5。 对于消息(type=MsgAppResp,reject=true,index=100,logTerm=5)，表示follower拒绝了leader的entries（可能是部分），由于follower节点已经包含index=100，term=5的entry。\nCommit 为 raftLog 的committed index。\nIndex和LogTerm字段是用于日志匹配的日志（即发送的日志的上一条日志）的index与term（用于日志匹配的term字段为LogTerm，消息的Term字段为该节点当前的term，部分消息需要自己指定，部分消息由send方法填充）。Entries字段保存了需要复制的日志条目。Commit字段为leader提交的最后一条日志的索引。\n 如何提高读性能，同时避免网络分区后重新选举出新leader出现的stale read？   TODO\n  CheckQuorum默认自动开启，同时开启Check Quorum会自动开启Leader Lease\n  raft.maybeSendAppend在发送 Message 时，会对 Message 中的entries大小做限制，maxSizePerMsg为1MB，因此entries在超过此大小时会如何处理？ raftLog.maybeAppend如何更新commit？\n   如果要发送的entries超过大小限制，则会发送多次\n pb.MsgSnapStatus消息以及ReportSnapshot的作用？   TODO\n candidate节点在赢得选举之后会append一条空的日志条目，其作用是什么？   candidate在当选leader后会在当前term为自己的日志追加一条空日志条目，并广播，以提交之前term的日志，具体可参考raft/raft.go中的handleAppendEntries()。\n 日志复制不匹配时的回退优化算法   TODO\n  对于follower节点，无论是处理MsgApp消息还是处理MsgSnap消息，返回的消息都是MsgAppResp。\n  在通过Transport发送Messages时，会忽略Message.To == 0的消息。\n  由于etcd的模块化设计，raft模块和存储网络模块是分开的，因此send方法只是将消息放入mailbox，而不是立刻将其发出（etcd/raft也没有通信模块）, 其与外界的交互都是通过Ready来进行处理的。因此，当follower收到MsgApp请求时，执行的操作实际上是（不考虑特殊情况）：\n    将新日志追加到unstable中。 将包含unstable的last index的MsgAppResp消息放入信箱，等待发送。   对于Ready的处理，角色不同处理的次序也是有区别的：\n  对于 follower 节点，是先将 entries， hardState， snapshot 保存到稳定的存储后再发送 Messages。 对于 leader 节点，可以在发送 Messages 的同时将 entries， hardState， snapshot持久化。   raft中的异常处理，例如 添加成员时leader正在进行leadTransfer，如果收到MsgProp的消息，这时会返回 ErrProposalDropped 如何处理？   TODO\n applyEntryNormal时有V2和V3请求，分别对应pb.Request和pb.InternalRaftRequest，其log对应：  167 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:49:48.188+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1835\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;Applying entry\u0026quot;,\u0026quot;index\u0026quot;:8,\u0026quot;term\u0026quot;:2,\u0026quot;type\u0026quot;:\u0026quot;EntryNormal\u0026quot;} 168 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:49:48.189+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1885\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;apply entry normal\u0026quot;,\u0026quot;consistent-index\u0026quot;:7,\u0026quot;entry-index\u0026quot;:8,\u0026quot;should-applyV3\u0026quot;:true} 169 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:49:48.189+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1908\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;applyEntryNormal\u0026quot;,\u0026quot;V2request\u0026quot;:\u0026quot;ID:16732981032079369986 Method:\\\u0026quot;PUT\\\u0026quot; Path:\\\u0026quot;/0/members/45d559f8148de837/attributes\\\u0026quot; Val:\\\u0026quot;{\\\\\\\u0026quot;name\\\\\\\u0026quot;:\\\\\\\u0026quot;infra4\\\\\\\u0026quot;,\\\\\\\u0026quot;clientURLs\\\\\\\u0026quot;:[\\\\\\\u0026quot;http://127.0.0.1:42379\\\\\\\u0026quot;]}\\\u0026quot; \u0026quot;} 206 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:49:48.206+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1835\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;Applying entry\u0026quot;,\u0026quot;index\u0026quot;:12,\u0026quot;term\u0026quot;:2,\u0026quot;type\u0026quot;:\u0026quot;EntryNormal\u0026quot;} 207 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:49:48.206+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1885\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;apply entry normal\u0026quot;,\u0026quot;consistent-index\u0026quot;:11,\u0026quot;entry-index\u0026quot;:12,\u0026quot;should-applyV3\u0026quot;:true} 208 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:49:48.206+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1912\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;applyEntryNormal\u0026quot;,\u0026quot;raftReq\u0026quot;:\u0026quot;header:\u0026lt;ID:13926956989250840580 \u0026gt; cluster_version_set:\u0026lt;ver:\\\u0026quot;3.6.0\\\u0026quot; \u0026gt; \u0026quot;} 261 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:52:35.450+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1835\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;Applying entry\u0026quot;,\u0026quot;index\u0026quot;:14,\u0026quot;term\u0026quot;:2,\u0026quot;type\u0026quot;:\u0026quot;EntryNormal\u0026quot;} 262 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:52:35.450+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1885\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;apply entry normal\u0026quot;,\u0026quot;consistent-index\u0026quot;:13,\u0026quot;entry-index\u0026quot;:14,\u0026quot;should-applyV3\u0026quot;:true} 263 {\u0026quot;level\u0026quot;:\u0026quot;debug\u0026quot;,\u0026quot;ts\u0026quot;:\u0026quot;2021-12-08T10:52:35.450+0800\u0026quot;,\u0026quot;caller\u0026quot;:\u0026quot;etcdserver/server.go:1912\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;applyEntryNormal\u0026quot;,\u0026quot;raftReq\u0026quot;:\u0026quot;header:\u0026lt;ID:3632572666012018439 \u0026gt; put:\u0026lt;key:\\\u0026quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\u0026quot; value:\\\u0026quot;\\\\026T\\\\316d\\\\230x\\\\326x\\\u0026quot; \u0026gt; \u0026quot;} 新加入的节点或者落后很多的节点，leader 会尝试发送快照数据给follower节点，maybeSendAppend方法在处理时会生成快照消息，如下所示：  snapshot, _ := r.raftLog.snapshot() pb.Message{ To: to, Type: pb.MsgSnap, Snapshot: snapshot, // 看起来有点多余 } 应用逻辑层通过Ready获取messages之后会将快照消息单独处理（将其发送到msgSnapC），applyAll 在收到快照消息后会调用 createMergedSnapshotMessage 生成合并的snap.Message消息后将其发送到peer端。而 createMergedSnapshotMessage 方法会根据当前 etcd progress 的 appliedt和appliedi重新生成新的 Metadata 和 Data (v2 store序列化后的数据)，所以上面raft层在生成 MsgSnap 消息时的 Snapshot 是多余的，虽然不影响。\nserializable read request 和 linearizable read request ?   Linearizability is one of the strongest single-object consistency models, and implies that every operation appears to take place atomically, in some order, consistent with the real-time ordering of those operations: e.g., if operation A completes before operation B begins, then B should logically take effect after A.\n  etcd 中默认是linearizable read，如果需要客户端serializable read，可以通过WithSerializable()进行设置，Serializable 请求适用于低延迟。\n 以Range为例，\nif !r.Serializable { err = s.linearizableReadNotify(ctx) trace.Step(\u0026#34;agreement among raft nodes before linearized reading\u0026#34;) if err != nil { return nil, err } } ReadOnlyOption 包含两种类型：\n ReadOnlySafe 通过与quorum个节点进行通信来保证只读请求的线性化，默认选项。 ReadOnlyLeaseBased 依赖领导者租约(leader lease)来保证只读请求的线性化，它会受clock drift的影响。  如果ReadOnlyOption 是 ReadOnlyLeaseBased 的时候必须开启CheckQuorum。\n Read index retry 中有个注释还没太理解\n    codes\nserver/etcdserver/server.go 299 NewServer() server/etcdserver/bootstrap.go 526 newRaftNode() server/etcdserver/bootstrap.go 268 bootstrapCluster() server/etcdserver/api/rafthttp/transport.go 175 Send() raft/node.go 241 RestartNode() Breakpoint 1 (enabled) at 0xfc67f5 for go.etcd.io/etcd/server/v3/etcdserver.NewServer() ./server/etcdserver/server.go:300 (1) Breakpoint 2 (enabled) at 0xfad002 for go.etcd.io/etcd/server/v3/etcdserver.bootstrapCluster() ./server/etcdserver/bootstrap.go:269 (1) ConfState #  raft/tracker/tracker.go 146 ConfState() server/storage/schema/confstate.go 在DB中保存或者读取 raft/confchange/restore.go raft/raft.go server/etcdserver/bootstrap.go 285 bootstrapExistingClusterNoWAL() raft/raft.go stepLeader() 1112 raft/raft.go maybeSendAppend() 432 raft/raft.go handleAppendEntries() 1498 snapshot 发送与接收 #  server/etcdserver/api/rafthttp/http.go 199 ServeHTTP() server/etcdserver/snapshot_merge.go server/etcdserver/server.go 906 applyAll() server/etcdserver/api/rafthttp/snapshot_sender.go 68 send() server/etcdserver/raft.go 246 start() 参考链接 #   etcd 注解版 raft doc etcd的raft实现之tracker\u0026amp;quorum etcd raft 处理流程图系列3-wal的存储和运行 深入浅出etcd/raft —— 0x05 Raft成员变更 raft: liveness problems during apply-time configuration change etcd learner design raft: implement fast log rejection Raft Consensus Protocol Made Simpler  "},{"id":1,"href":"/posts/prometheus-wal/","title":"Prometheus WAL源码阅读","section":"Blog","content":" 概述 #  WAL(Write-ahead logging, 预写日志)是关系型数据库中利用日志来实现事务性和持久性的一种技术，即在某个操作之前先将这个事情记录下来，以便之后对数据进行回滚，重试等操作保证数据的可靠性。\nPrometheus为了防止丢失暂存在内存中的还未被写入磁盘的监控数据，引入了WAL机制。WAL被分割成默认大小为128M的文件段（segment），之前版本默认大小是256M，文件段以数字命名，长度为8位的整形。WAL的写入单位是页（page），每页的大小为32KB，所以每个段大小必须是页的大小的整数倍。每个文件段都有一个“==已使用的页？==”属性来标识在该段中已经分配的页数目，如果WAL一次性写入的页数超过一个段的空闲页数，就会创建一个新的文件段来保存这些页，从而确保一次性写入的页不会跨段存储。\nconst ( DefaultSegmentSize = 128 * 1024 * 1024 // 128 MB  pageSize = 32 * 1024 // 32KB  recordHeaderSize = 7 ) 本文是在prometheus tsdb部分源码阅读之wal.LogSeries基础上进行扩展，由于tsdb/wal.go文件中定义的WAL接口以及相关方法已经deprecated，如下所示。因此本文针对tsdb/wal/wal.go文件进行分析。\n// WAL is a write ahead log that can log new series labels and samples. // It must be completely read before new entries are logged. // // DEPRECATED: use wal pkg combined with the record codex instead. type WAL interface { Reader() WALReader LogSeries([]RefSeries) error LogSamples([]RefSample) error LogDeletes([]Stone) error Truncate(mint int64, keep func(uint64) bool) error Close() error }  Prometheus storage hierarchy #  (ENV) 🍺 /Users/xsky/go/src/github.com/microyahoo/prometheus/data ☞ tree -h . ├── [ 192] 01DPE8T5XPQ9ZYHSNJYBJBKGR6 │ ├── [ 96] chunks │ │ └── [7.1K] 000001 │ ├── [ 22K] index │ ├── [ 272] meta.json │ └── [ 9] tombstones ├── [ 0] lock ├── [ 20K] queries.active └── [ 256] wal ├── [ 0] 00000050 ├── [ 0] 00000051 ├── [ 0] 00000052 ├── [ 0] 00000053 ├── [ 10K] 00000054 └── [ 96] checkpoint.000049 └── [ 32K] 00000000 4 directories, 12 files 从上面目录结构可以看出wal主要包含segment文件，checkpoint目录。\n// WAL is a write ahead log that stores records in segment files. // It must be read from start to end once before logging new data. // If an error occurs during read, the repair procedure must be called // before it\u0026#39;s safe to do further writes. // // Segments are written to in pages of 32KB, with records possibly split // across page boundaries. // Records are never split across segments to allow full segments to be // safely truncated. It also ensures that torn writes never corrupt records // beyond the most recent segment. type WAL struct { dir string logger log.Logger segmentSize int mtx sync.RWMutex segment *Segment // Active segment.  donePages int // Pages written to the segment.  page *page // Active page.  stopc chan chan struct{} actorc chan func() closed bool // To allow calling Close() more than once without blocking.  compress bool snappyBuf []byte fsyncDuration prometheus.Summary pageFlushes prometheus.Counter pageCompletions prometheus.Counter truncateFail prometheus.Counter truncateTotal prometheus.Counter currentSegment prometheus.Gauge } // Segment represents a segment file. type Segment struct { *os.File dir string i int }  Create Segment #  创建segment主要是通过New方法或者NewSize方法。其中NewSize可以指定segment的大小，New方法传入的是默认的segment大小，即128M。加载DB时如果WAL enabled的话，则会调用NewSize创建新的segment，如下所示。下面对NewSize进行展开。\nwlog, err = wal.NewSize(l, r, filepath.Join(dir, \u0026quot;wal\u0026quot;), segmentSize, opts.WALCompression)  首先判断段大小是否是page的整数倍。 如果wal目录不存在的话则创建wal目录。 创建WAL数据结构。因为WAL是与active segment关联的，所以WAL segmentSize即为指定的segmentSize。 查找目前WAL中所有的segment记录。因为segment是按照数字命名并递增的，所以其名字即为索引，其内部表述为segmentRef，name为其文件名，即前缀为0填充的八位整形表示，index即为其整形表示。  type segmentRef struct { name string index int }  上面步骤获取到last segment之后，下一个要写入的segment index即为last+1，创建新的segment。 将新创建的segment设置为WAL的active segment，同时根据segment文件大小设置WAL donePages，将WAL currentSegment设置为新创建的segment的index。 启动新的goroutine执行actorc通道发送过来的func。主要用于执行比较耗时的操作，例如将segment中的数据fsync到disk中。   WAL Repair #   Repair attempts to repair the WAL based on the error. It discards all data after the corruption.\n 需要注意的是Repair仅能修复CorruptionErr。CorruptionErr中指定了目录，段，偏移量以及具体的错误信息。\n// CorruptionErr is an error that\u0026#39;s returned when corruption is encountered. type CorruptionErr struct { Dir string Segment int Offset int64 Err error }  首先获取wal目录中所有的segments。 删除CorruptionErr.Segment索引之后的所有的segments。 关闭WAL的active segment。 将CorruptionErr.Segment索引的segment加上.repair后缀并重命名。 创建一个新的segment文件，其index为CorruptionErr.Segment，即Corruption segment重命名之后重新创建一个新的segment文件，并将WAL的active segment指向新创建的segment。 将Corruption segment中的数据读到新创建的segment文件中，读到CorruptionErr.Offset为止。  遍历读取corrupted segment中的records，将其写入new segment中。   将active page刷入file。 关闭corrupted segment文件，并删除。 创建一个新的segment文件，其index为CorruptionErr.Segment的index+1，并将active segment指向新创建的segment。  下面截取tsdb/wal/wal.go文件中的部分Repair的代码进行分析。\n// 打开corrupted segment文件并读取其中的records。  r := NewReader(bufio.NewReader(f)) // 下面WAL Reader部分有详细解释  for r.Next() { // Add records only up to the where the error was.  // 读取到出错的地方为止。  if r.Offset() \u0026gt;= cerr.Offset { break } // 下面着重介绍此方法  if err := w.Log(r.Record()); err != nil { return errors.Wrap(err, \u0026#34;insert record\u0026#34;) } } // We expect an error here from r.Err(), so nothing to handle.  // We need to pad to the end of the last page in the repaired segment  if err := w.flushPage(true); err != nil { return errors.Wrap(err, \u0026#34;flush page in repair\u0026#34;) } // We explicitly close even when there is a defer for Windows to be  // able to delete it. The defer is in place to close it in-case there  // are errors above.  if err := f.Close(); err != nil { return errors.Wrap(err, \u0026#34;close corrupted file\u0026#34;) } // 删除.repair文件  if err := os.Remove(tmpfn); err != nil { return errors.Wrap(err, \u0026#34;delete corrupted segment\u0026#34;) } // Explicitly close the segment we just repaired to avoid issues with Windows.  s.Close() // We always want to start writing to a new Segment rather than an existing  // Segment, which is handled by NewSize, but earlier in Repair we\u0026#39;re deleting  // all segments that come after the corrupted Segment. Recreate a new Segment here.  // 创建新的segment file，并将active segment指向此新创建的segment file  s, err = CreateSegment(w.dir, cerr.Segment+1) if err != nil { return err } if err := w.setSegment(s); err != nil { return err } return nil Repair的核心就是将corrupted segment文件中的数据写入新的segment中，然后删除corrupted segment文件。下面着重介绍其写入过程，主要是调用WAL的log方法。\n// log writes rec to the log and forces a flush of the current page if: // - the final record of a batch // - the record is bigger than the page size // - the current page is full. func (w *WAL) log(rec []byte, final bool) error { // When the last page flush failed the page will remain full.  // When the page is full, need to flush it before trying to add more records to it.  // 如果WAL的active page已满，则flush到file，并重置此page  if w.page.full() { if err := w.flushPage(true); err != nil { return err } } // If the record is too big to fit within the active page in the current  // segment, terminate the active segment and advance to the next one.  // This ensures that records do not cross segment boundaries.  left := w.page.remaining() - recordHeaderSize // Free space in the active page.  left += (pageSize - recordHeaderSize) * (w.pagesPerSegment() - w.donePages - 1) // Free pages in the active segment.  // 如果record的长度大于active segment的剩余可用空间，则创建新的segment  if len(rec) \u0026gt; left { // 1. 如果active page已分配大小不为0，则flush page到file。  // 2. 创建新的segment file。  // 3. 将上一个segment file的数据fsync到磁盘。  if err := w.nextSegment(); err != nil { return err } } compressed := false if w.compress \u0026amp;\u0026amp; len(rec) \u0026gt; 0 { // The snappy library uses `len` to calculate if we need a new buffer.  // In order to allocate as few buffers as possible make the length  // equal to the capacity.  // 如果WAL compress enabled，则将record数据编码为snappyBuf，  // 将rec指向压缩后的snappyBuf数据记录。  w.snappyBuf = w.snappyBuf[:cap(w.snappyBuf)] w.snappyBuf = snappy.Encode(w.snappyBuf, rec) if len(w.snappyBuf) \u0026lt; len(rec) { rec = w.snappyBuf compressed = true } } // Populate as many pages as necessary to fit the record.  // Be careful to always do one pass to ensure we write zero-length records.  for i := 0; i == 0 || len(rec) \u0026gt; 0; i++ { p := w.page // Find how much of the record we can fit into the page.  var ( l = min(len(rec), (pageSize-p.alloc)-recordHeaderSize) part = rec[:l] // buf指向page.buf的offset为page.alloc  buf = p.buf[p.alloc:] typ recType ) switch { case i == 0 \u0026amp;\u0026amp; len(part) == len(rec): typ = recFull case len(part) == len(rec): typ = recLast case i == 0: typ = recFirst default: typ = recMiddle } if compressed { typ |= snappyMask } // 判断record的type和是否compress，并将其写入buf的第一个字节。  // 接着写入2字节的长度为min(len(record), (pageSize-p.alloc)-recordHeaderSize)，  // 也就是说有可能record的长度大于active page所能分配的最大长度，  // 这样record就会跨page，但是不能跨segment。  // 然后写入4个字节的CRC  buf[0] = byte(typ) crc := crc32.Checksum(part, castagnoliTable) binary.BigEndian.PutUint16(buf[1:], uint16(len(part))) binary.BigEndian.PutUint32(buf[3:], crc) // 紧接着header写入record数据记录，可能是一部分。  copy(buf[recordHeaderSize:], part) p.alloc += len(part) + recordHeaderSize // 如果page已满，则flush到file中。  if w.page.full() { if err := w.flushPage(true); err != nil { return err } } rec = rec[l:] } // If it\u0026#39;s the final record of the batch and the page is not empty, flush it.  if final \u0026amp;\u0026amp; w.page.alloc \u0026gt; 0 { if err := w.flushPage(false); err != nil { return err } } return nil } WAL Reader #  // Reader reads WAL records from an io.Reader. type Reader struct { rdr io.Reader err error rec []byte snappyBuf []byte buf [pageSize]byte total int64 // Total bytes processed.  curRecTyp recType // Used for checking that the last record is not torn. } 其中Reader从rdr中读取records，相当于把io.Reader做了一层包装；buf为大小为pageSize的字节数组。\n+--------------------------------------------------+ | Reader.buf | +-----------------------------------+--------------+ | hdr | buf | +-----------+----------+------------+--------------+ | type \u0026lt;1b\u0026gt; | len \u0026lt;2b\u0026gt; | CRC32 \u0026lt;4b\u0026gt; | data \u0026lt;bytes\u0026gt; | +-----------+----------+------------+--------------+ the record fragment is encoded as:\n+-----------+----------+------------+--------------+ | type \u0026lt;1b\u0026gt; | len \u0026lt;2b\u0026gt; | CRC32 \u0026lt;4b\u0026gt; | data \u0026lt;bytes\u0026gt; | +-----------+----------+------------+--------------+ The type flag has the following states:\n 0: rest of page will be empty 1: a full record encoded in a single fragment 2: first fragment of a record 3: middle fragment of a record 4: final fragment of a record  其中type占用一个byte，由于type flag只有五种状态，3 bits就可以表示了。前4个 bit未分配，第5个bit表示是否压缩，最后三个bit表示record type。\n+--------------------+-------------------------------+------------------------+ | 4 bits unallocated | 1 bit snappy compression flag | 3 bit record type | +--------------------+-------------------------------+------------------------+ // Next advances the reader to the next records and returns true if it exists. // It must not be called again after it returned false. func (r *Reader) Next() bool { err := r.next() if errors.Cause(err) == io.EOF { // The last WAL segment record shouldn\u0026#39;t be torn(should be full or last).  // The last record would be torn after a crash just before  // the last record part could be persisted to disk.  if r.curRecTyp == recFirst || r.curRecTyp == recMiddle { r.err = errors.New(\u0026#34;last record is torn\u0026#34;) } return false } r.err = err return r.err == nil } func (r *Reader) next() (err error) { // We have to use r.buf since allocating byte arrays here fails escape  // analysis and ends up on the heap, even though it seemingly should not.  // 前面7个byte代表header，后面的为data  hdr := r.buf[:recordHeaderSize] buf := r.buf[recordHeaderSize:] r.rec = r.rec[:0] r.snappyBuf = r.snappyBuf[:0] i := 0 for { // 首先从rdr中读取一个字节  if _, err = io.ReadFull(r.rdr, hdr[:1]); err != nil { return errors.Wrap(err, \u0026#34;read first header byte\u0026#34;) } r.total++ // 获取record type，并判断是否压缩  r.curRecTyp = recTypeFromHeader(hdr[0]) compressed := hdr[0]\u0026amp;snappyMask != 0 // Gobble up zero bytes.  // 如果record type为recPageTerm，代表后面page剩余数据全部为0填充。即第一个byte为type，后面全是0。  if r.curRecTyp == recPageTerm { // recPageTerm is a single byte that indicates the rest of the page is padded.  // If it\u0026#39;s the first byte in a page, buf is too small and  // needs to be resized to fit pageSize-1 bytes.  buf = r.buf[1:] // We are pedantic and check whether the zeros are actually up  // to a page boundary.  // It\u0026#39;s not strictly necessary but may catch sketchy state early.  k := pageSize - (r.total % pageSize) if k == pageSize { continue // Initial 0 byte was last page byte.  } n, err := io.ReadFull(r.rdr, buf[:k]) if err != nil { return errors.Wrap(err, \u0026#34;read remaining zeros\u0026#34;) } r.total += int64(n) for _, c := range buf[:k] { if c != 0 { return errors.New(\u0026#34;unexpected non-zero byte in padded page\u0026#34;) } } continue } // 读取剩余的6个byte，分别代表length和crc  n, err := io.ReadFull(r.rdr, hdr[1:]) if err != nil { return errors.Wrap(err, \u0026#34;read remaining header\u0026#34;) } r.total += int64(n) var ( length = binary.BigEndian.Uint16(hdr[1:]) crc = binary.BigEndian.Uint32(hdr[3:]) ) if length \u0026gt; pageSize-recordHeaderSize { return errors.Errorf(\u0026#34;invalid record size %d\u0026#34;, length) } // 读取长度为length的数据，并计算其crc值是否与header中的crc相等。  n, err = io.ReadFull(r.rdr, buf[:length]) if err != nil { return err } r.total += int64(n) if n != int(length) { return errors.Errorf(\u0026#34;invalid size: expected %d, got %d\u0026#34;, length, n) } if c := crc32.Checksum(buf[:length], castagnoliTable); c != crc { return errors.Errorf(\u0026#34;unexpected checksum %x, expected %x\u0026#34;, c, crc) } // 如果为压缩数据，则将其存放在snappyBuf中，后面读取完成后进行decode。  if compressed { r.snappyBuf = append(r.snappyBuf, buf[:length]...) } else { r.rec = append(r.rec, buf[:length]...) } if err := validateRecord(r.curRecTyp, i); err != nil { return err } if r.curRecTyp == recLast || r.curRecTyp == recFull { if compressed \u0026amp;\u0026amp; len(r.snappyBuf) \u0026gt; 0 { // The snappy library uses `len` to calculate if we need a new buffer.  // In order to allocate as few buffers as possible make the length  // equal to the capacity.  // 将压缩的数据进行解码。  r.rec = r.rec[:cap(r.rec)] r.rec, err = snappy.Decode(r.rec, r.snappyBuf) return err } return nil } // Only increment i for non-zero records since we use it  // to determine valid content record sequences.  i++ } } Next方法从rdr中读取record，如果存在则返回true。每次最多读取pageSize-recordHeaderSize大小的数据，直到读取完整的record，如果数据被压缩，则需要decode，最后的record存储在Reader.rec字段中。\n问题点 #   为什么需要recPageTerm类型，这样是不是浪费了一整个page大小的空间？ record代表什么？ 为什么length不能大于pageSize-recordHeaderSize？ record的大小会大于segment吗？   References #   WAL disk format prometheus tsdb部分源码阅读之wal.LogSeries 详解varint编码原理 RocksDB WAL file format  "},{"id":2,"href":"/posts/alertmanager/","title":"Alert Manager","section":"Blog","content":"AlertManager #   Architecture #     Alertmanager作为一个独立的组件，负责接收并处理来自Prometheus Server(也可以是其它的客户端程序)的告警信息。Alertmanager可以对这些告警信息进行进一步的处理，比如当接收到大量重复告警时能够消除重复的告警信息，同时对告警信息进行分组并且路由到正确的通知方，Prometheus内置了对邮件，Slack等多种通知方式的支持，同时还支持与Webhook的集成，以支持更多定制化的场景。同时AlertManager还提供了静默和告警抑制机制来对告警通知行为进行优化。\n 客户端通过POST请求向AlertManager推送告警信息。 每条告警信息中的labels可用于唯一识别告警信息并用于去重。    AlertManager主要分为两个部分，路由(router)和接收器(receiver)。告警消息先被经过路由树，然后被分配到对应的接收器中。路由树是由预先设定的路由规则生成的。其高可用架构如上图所示，具体流程如下：\n Prometheus会通过调用AlertManager提供的告警接口将原始的告警消息发送到AlertManager。 AlertManager的API除了接收告警，还接收静默请求，将其分别保存到各自的provider里。 provider提供了一个订阅（subscribe）接口，这样Dispatcher组件便可以获取告警数据，并对数据进行分组，通过用户预先设置的规则进入告警抑制阶段或静默阶段。 如果通过了上面的告警静默阶段，则进入路由分发阶段，最终发送通知。    上报数据格式 #  [ { \u0026quot;labels\u0026quot;: { \u0026quot;alertname\u0026quot;: \u0026quot;\u0026lt;requiredAlertName\u0026gt;\u0026quot;, \u0026quot;\u0026lt;labelname\u0026gt;\u0026quot;: \u0026quot;\u0026lt;labelvalue\u0026gt;\u0026quot;, ... }, \u0026quot;annotations\u0026quot;: { \u0026quot;\u0026lt;labelname\u0026gt;\u0026quot;: \u0026quot;\u0026lt;labelvalue\u0026gt;\u0026quot;, }, \u0026quot;startsAt\u0026quot;: \u0026quot;\u0026lt;rfc3339\u0026gt;\u0026quot;, \u0026quot;endsAt\u0026quot;: \u0026quot;\u0026lt;rfc3339\u0026gt;\u0026quot;, \u0026quot;generatorURL\u0026quot;: \u0026quot;\u0026lt;generator_url\u0026gt;\u0026quot; }, ... ]  其中：  告警信息的Fingerprint是通过labels来进行计算的。 startAt和endsAt在provider的告警合并会用到。     Alert Provider #   Prometheus或者告警发送系统可以通过API的方式发送给Alertmanager，收到告警后将告警分别存储在Alert Provider中（当前实现是存储在内存中，可以通过接口的方式自行实现其他存储方式比如MySQL或者ES）。 已解决的alerts会定期地从provider中清除，用户可以定义相应的回调函数，在alerts被删除时进行相应的回调处理。 Alert Provider收到告警信息后对相同的指标数据进行合并处理。  // Alerts gives access to a set of alerts. All methods are goroutine-safe. type Alerts interface { // Subscribe returns an iterator over active alerts that have not been // resolved and successfully notified about. // They are not guaranteed to be in chronological order. Subscribe() AlertIterator // GetPending returns an iterator over all alerts that have // pending notifications. GetPending() AlertIterator // Get returns the alert for a given fingerprint. Get(model.Fingerprint) (*types.Alert, error) // Put adds the given alert to the set. Put(...*types.Alert) error }  Silence Provider #   Dispatcher #   Dispatcher sorts incoming alerts into aggregation groups and assigns the correct notifiers to each. AlertManager内部的Dispatcher通过订阅的方式获得告警信息更新（获得Alerts的迭代器，通过for循环不断的获得发送到信道中的Alerts, 通过route的match函数获得匹配的route对象（比如基于标签的正则表达，传递到不同的邮件或者slack信道路由）,并且每隔一段时间将执行一次清理操作（当aggregate group中的告警数量为空的时候），删除之前的记录。收到的Alert通过标签匹配的方式被送到不同的聚合组中等待Pipeline流程进行处理。  Aggregate group #   aggrGroup aggregates alert fingerprints into groups to which a common set of routing options applies. It emits notifications in the specified intervals. 聚合组aggregate group用来管理具有相同属性信息的告警，通过将相同类型的告警进行分组可以统一的管理，因为有时候告警处理是大量同时出现的（比如一个数据中心的失效将导致成百上千的告警产生，通过分组可以聚合相同标签到一个邮件或者接收者中）。分组创建将依赖于处理route路由和告警的labels标签，不同的告警labels将产生不同的聚合组，所有接收到的告警将首先计算一个聚合组的Fingerprint如果找到则直接插入到该组，否则创建一个新的聚合组，每次新创建的聚合组都会启动一个goroutine来执行实际的pipeline work.   Inhibitor #   An Inhibitor determines whether a given label set is muted based on the currently active alerts and a set of inhibition rules. It implements the Muter interface. Inhibitor用于管理相同的告警配置， 比如下面的配置定义了当告警名称alertname一致的时候，如果严重告警存在的时候，途同级别告警将被过滤掉。 查询流程上将获得的alert的label进行检查，匹配检查的内容满足target匹配但是source不匹配的标记为Inhibited.   Silencer #   Silencer用来取消告警，比如直接配置告警在某一段时间内不触发任何消息，可以基于正则表达式的匹配，该配置可以通过alertmanager的WebUI或者API接口配置。 当流程传递到Silence步骤时候，Silence模块将循环检查每一个告警是否满足匹配，比如设置某一个告警标签出现后取消告警。当查询结束后返回一个sils（Silence的结构体，用来指定某一类告警的Silence在一段时间内的处理对象。）一个告警可能会被多个Silence同时管理。 同时要实现集群管理，彼此之间的Silence状态也要共享（告警发送给多个AM），因此系统设计的时候加入了SilenceProvider来进行集群之间的Silence管理,彼此之间通过protoBuf来进行数据状态的同步。同时集群在接收到告警后也要进行通知，告知其他的节点关于告警的处理状态，防止多个通知同时被发送。   Notify Provider #   Router #   Receiver Stage #  Wait #   等待间隔用来设置发送告警的等待时间，对于集群操作中，需要根据不同的peer设置不同的超时时间，如果仅仅一个Server本身，等待间隔设置为0；  Dedup #   Dedup Stage用于管理告警的去重，传递的参数中包含了一个NotificationLog, 用来保存告警的发送记录。当有多个机器组成集群的时候，NotificationLog会通过协议去进行通信，传递彼此的记录信息，加入集群中的A如果发送了告警，该记录会传递给B机器，并进行merge操作，这样B机器在发送告警的时候如果查询已经发送，则不再进行告警发送。  Retry #   Retry Stage利用backoff策略来管理告警的重发，对于没有发送成功的告警将不断重试，直到超时。  Set Notify #    Set Notifies Stage用来设置发送告警的信息到nfLog，该模块仅仅用于被该Alert Manager发送的告警的记录（Retry组件传递的alerts和Dedup组件中发送出去的告警信息）。\n  Integration定义一个集成路由组件，包含用户的配置信息和名称以及发送告警的实现。自定义的notify路由需要满足该Notifier接口，实现Notify方法。\n   Examples #  groups: - name: httpd rules: - alert: httpd_down expr: probe_success{instance=\u0026quot;http://httpd:80\u0026quot;,job=\u0026quot;httpd\u0026quot;} == 0 for: 1m labels: severity: critical annotations: summary: \u0026quot;httpd is down\u0026quot;  Prometheus Server will wait for 1m and if the expression meets the condition for 1m, now Prometheus Server has to fire alert and forward to AlertManager. Until now, Prometheus knows how to connect to AlertManager and when to fire and forward alerts to AlertManager.  route: repeat_interval: 2h receiver: email-1 routes: - match: alertname: httpd_down receiver: email-1 - match: alertname: nginx_down receiver: email-2  These routes and receivers are defined in the AlertManager configuration file by the parent element called route. The parent route element has child routes which an alert follows in order to reach to its receiver based upon the match label as we will see in a bit.  http://localhost:9090/api/v1/alertmanagers { \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: { \u0026quot;activeAlertmanagers\u0026quot;: [ { \u0026quot;url\u0026quot;: \u0026quot;http://127.0.0.1:9093/api/v1/alerts\u0026quot; } ], \u0026quot;droppedAlertmanagers\u0026quot;: [] } } curl -X GET http://10.255.101.73:9090/api/v1/alerts { \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: { \u0026quot;alerts\u0026quot;: [ { \u0026quot;labels\u0026quot;: { \u0026quot;alertname\u0026quot;: \u0026quot;内存使用率过高\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;127.0.0.1:9100\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;node\u0026quot;, \u0026quot;severity\u0026quot;: \u0026quot;warning\u0026quot; }, \u0026quot;annotations\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;127.0.0.1:9100 of job node内存使用率超过80%,当前使用率[59.74335527485338].\u0026quot;, \u0026quot;summary\u0026quot;: \u0026quot;Instance 127.0.0.1:9100 内存使用率过高\u0026quot; }, \u0026quot;state\u0026quot;: \u0026quot;firing\u0026quot;, \u0026quot;activeAt\u0026quot;: \u0026quot;2019-08-23T11:27:34.027571952Z\u0026quot;, \u0026quot;value\u0026quot;: 59.74335527485338 } ] } } http://10.255.101.73:9093/api/v2/alerts [ { \u0026quot;annotations\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;10.255.101.74:8051 of job default go_goroutines \u0026gt; 100,当前go_goroutines: [137].\u0026quot;, \u0026quot;summary\u0026quot;: \u0026quot;Instance 10.255.101.74:8051 go_goroutines \u0026gt; 100\u0026quot; }, \u0026quot;endsAt\u0026quot;: \u0026quot;2019-08-31T06:19:27.344Z\u0026quot;, \u0026quot;fingerprint\u0026quot;: \u0026quot;0d38358ac4713623\u0026quot;, \u0026quot;receivers\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default-receiver\u0026quot; } ], \u0026quot;startsAt\u0026quot;: \u0026quot;2019-08-23T11:28:27.344Z\u0026quot;, \u0026quot;status\u0026quot;: { \u0026quot;inhibitedBy\u0026quot;: [], \u0026quot;silencedBy\u0026quot;: [], \u0026quot;state\u0026quot;: \u0026quot;active\u0026quot; }, \u0026quot;updatedAt\u0026quot;: \u0026quot;2019-08-31T14:16:27.348+08:00\u0026quot;, \u0026quot;generatorURL\u0026quot;: \u0026quot;http://ceph-1:9090/graph?g0.expr=go_goroutines+%3E+100\u0026amp;g0.tab=1\u0026quot;, \u0026quot;labels\u0026quot;: { \u0026quot;alertname\u0026quot;: \u0026quot;go_goroutines大于100\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;10.255.101.74:8051\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;severity\u0026quot;: \u0026quot;warning\u0026quot; } } ] http://10.255.101.73:9093/api/v1/alerts { \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: [ { \u0026quot;labels\u0026quot;: { \u0026quot;alertname\u0026quot;: \u0026quot;go_goroutines大于100\u0026quot;, \u0026quot;instance\u0026quot;: \u0026quot;10.255.101.74:8051\u0026quot;, \u0026quot;job\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;severity\u0026quot;: \u0026quot;warning\u0026quot; }, \u0026quot;annotations\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;10.255.101.74:8051 of job default go_goroutines \u0026gt; 100,当前go_goroutines: [135].\u0026quot;, \u0026quot;summary\u0026quot;: \u0026quot;Instance 10.255.101.74:8051 go_goroutines \u0026gt; 100\u0026quot; }, \u0026quot;startsAt\u0026quot;: \u0026quot;2019-08-23T11:28:27.344378042Z\u0026quot;, \u0026quot;endsAt\u0026quot;: \u0026quot;2019-08-31T06:21:27.344378042Z\u0026quot;, \u0026quot;generatorURL\u0026quot;: \u0026quot;http://ceph-1:9090/graph?g0.expr=go_goroutines+%3E+100\u0026amp;g0.tab=1\u0026quot;, \u0026quot;status\u0026quot;: { \u0026quot;state\u0026quot;: \u0026quot;active\u0026quot;, \u0026quot;silencedBy\u0026quot;: [], \u0026quot;inhibitedBy\u0026quot;: [] }, \u0026quot;receivers\u0026quot;: [ \u0026quot;default-receiver\u0026quot; ], \u0026quot;fingerprint\u0026quot;: \u0026quot;0d38358ac4713623\u0026quot; } ] } References #   AlertManager github SENDING ALERTS CONFIGURATION NOTIFICATION TEMPLATE REFERENCE Understanding Prometheus AlertManager Prometheus高可用(4)：Alertmanager高可用 Prometheus AlertManager代码阅读笔记 Prometheus AlertManager代码阅读笔记 Notify组件 Alertsnitch Prometheus integrations Understanding and extending prometheus alertmanager Hands-On Infrastructure Monitoring with Prometheus 搞搞 Prometheus: Alertmanager  "},{"id":3,"href":"/posts/open-falcon/","title":"Open Falcon","section":"Blog","content":"Open Faclon #   Architecture #   Faclon-agent #  Falcon-agent用于数据的采集，它会定期地将metric数据通过jsonRPC上报到Transfer，其上报的metric数据格式为：\nData model #  open-falcon采用和opentsdb相同的数据格式：metric、endpoint加多组key value tags。例如：\n{ metric: load.1min, endpoint: open-falcon-host, tags: srv=falcon,idc=aws-sgp,group=az1, value: 1.5, timestamp: `date +%s`, counterType: GAUGE, step: 60 }  Transfer #   Transfer接收到agent上报的metric数据后，经过一定的处理（将tags字符串转化为map），然后上报到Graph, Judge和TSDB。  提供数据接收接口供Agent和自定义脚本push监控数据。 对接收到的数据做合法性校验，规整。 针对每个后端实例维护一个RPC连接池。 准备内存Queue中转监控数据。 根据一致性哈希将Queue中的数据转发给Judge和Graph。 当后端宕机的时候做少量数据缓存，提供重试机制。     Heartbeat Server #   HBS主要有如下功能：  agent发送心跳信息给HBS的时候，会把hostname、ip、agent version、plugin version等信息告诉HBS，HBS负责更新host表。 将IP白名单分发到所有的agent。 告诉各个agent应该执行哪些插件。 告诉各个agent应该监听哪些端口，进程。 缓存监控策略。  HBS去获取所有的报警策略缓存在内存里，然后Judge去向HBS请求。其中Judge通过rpc调用来获取。  在配置报警策略的时候配置了报警级别，比如P0/P1/P2等等，每个级别的报警都会对应不同的redis队列。         Judge #   因为监控系统数据量比较大，一台机器显然是搞不定的，所以必须要有个数据分片方案。Transfer通过一致性哈希来分片，每个Judge就只需要处理一小部分数据就可以了。 同时Judge会定期地通过RPC从Heartbeat Server同步Strategy和Expression用于告警的判定。 Judge接收到Transfer的metric数据后首先是否有针对其的Strategy和Expression，如果没有则直接跳过，如果有则进行告警判定。 Judge会将判定结果以Event的形式发送到Redis缓存中。   Alarm #   Alarm从redis缓存中获取Judge推送的Event后，根据Event的优先级分别进行处理。 Alarm从redis队列分别获取高优先级的Event和低优先级的Event，其分别位于highQueues和lowQueues，其中highQueues中配置的几个event队列中的事件是不会做告警合并的，lowQueues会做告警合并。  按照优先级轮询Redis读取告警事件。 对需要回调的告警事件回调业务系统接口。 对高优先级告警事件直接生成告警邮件和短信。 对低优先级告警事件做合并。 提供web页面展示当前未恢复的告警。   制定邮件，短信发送的接口规范。   Nodata #   nodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善。    Graph #   References #   Open-falcon falcon-plus Falcon+ API Nodata 文档 心跳服务器 Falcon-HBS 源码解读视频 open-falcon 2.0文档 open-falcon部署与架构解析 数据采集模块 Falcon-Agent 源码解读 运维监控视频  "}]