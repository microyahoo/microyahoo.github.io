# Prometheus WALæºç é˜…è¯»

---
## æ¦‚è¿°
WAL(Write-ahead logging, é¢„å†™æ—¥å¿—)æ˜¯å…³ç³»å‹æ•°æ®åº“ä¸­åˆ©ç”¨æ—¥å¿—æ¥å®ç°äº‹åŠ¡æ€§å’ŒæŒä¹…æ€§çš„ä¸€ç§æŠ€æœ¯ï¼Œå³åœ¨æŸä¸ªæ“ä½œä¹‹å‰å…ˆå°†è¿™ä¸ªäº‹æƒ…è®°å½•ä¸‹æ¥ï¼Œä»¥ä¾¿ä¹‹åå¯¹æ•°æ®è¿›è¡Œå›æ»šï¼Œé‡è¯•ç­‰æ“ä½œä¿è¯æ•°æ®çš„å¯é æ€§ã€‚

Prometheusä¸ºäº†é˜²æ­¢ä¸¢å¤±æš‚å­˜åœ¨å†…å­˜ä¸­çš„è¿˜æœªè¢«å†™å…¥ç£ç›˜çš„ç›‘æ§æ•°æ®ï¼Œå¼•å…¥äº†WALæœºåˆ¶ã€‚WALè¢«åˆ†å‰²æˆé»˜è®¤å¤§å°ä¸º128Mçš„æ–‡ä»¶æ®µï¼ˆsegmentï¼‰ï¼Œä¹‹å‰ç‰ˆæœ¬é»˜è®¤å¤§å°æ˜¯256Mï¼Œæ–‡ä»¶æ®µä»¥æ•°å­—å‘½åï¼Œé•¿åº¦ä¸º8ä½çš„æ•´å½¢ã€‚WALçš„å†™å…¥å•ä½æ˜¯é¡µï¼ˆpageï¼‰ï¼Œæ¯é¡µçš„å¤§å°ä¸º32KBï¼Œæ‰€ä»¥æ¯ä¸ªæ®µå¤§å°å¿…é¡»æ˜¯é¡µçš„å¤§å°çš„æ•´æ•°å€ã€‚æ¯ä¸ªæ–‡ä»¶æ®µéƒ½æœ‰ä¸€ä¸ªâ€œ==å·²ä½¿ç”¨çš„é¡µï¼Ÿ==â€å±æ€§æ¥æ ‡è¯†åœ¨è¯¥æ®µä¸­å·²ç»åˆ†é…çš„é¡µæ•°ç›®ï¼Œå¦‚æœWALä¸€æ¬¡æ€§å†™å…¥çš„é¡µæ•°è¶…è¿‡ä¸€ä¸ªæ®µçš„ç©ºé—²é¡µæ•°ï¼Œå°±ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„æ–‡ä»¶æ®µæ¥ä¿å­˜è¿™äº›é¡µï¼Œä»è€Œç¡®ä¿ä¸€æ¬¡æ€§å†™å…¥çš„é¡µ**ä¸ä¼šè·¨æ®µå­˜å‚¨**ã€‚
```
const (
     DefaultSegmentSize = 128 * 1024 * 1024 // 128 MB
     pageSize           = 32 * 1024         // 32KB
     recordHeaderSize   = 7
)
```

æœ¬æ–‡æ˜¯åœ¨[prometheus tsdbéƒ¨åˆ†æºç é˜…è¯»ä¹‹wal.LogSeries](https://www.jianshu.com/p/e0144be9692a)åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•ï¼Œç”±äº`tsdb/wal.go`æ–‡ä»¶ä¸­å®šä¹‰çš„WALæ¥å£ä»¥åŠç›¸å…³æ–¹æ³•å·²ç»deprecatedï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚å› æ­¤æœ¬æ–‡é’ˆå¯¹`tsdb/wal/wal.go`æ–‡ä»¶è¿›è¡Œåˆ†æã€‚

```
// WAL is a write ahead log that can log new series labels and samples.
// It must be completely read before new entries are logged.
//
// DEPRECATED: use wal pkg combined with the record codex instead.
type WAL interface {
    Reader() WALReader
    LogSeries([]RefSeries) error
    LogSamples([]RefSample) error
    LogDeletes([]Stone) error
    Truncate(mint int64, keep func(uint64) bool) error
    Close() error
}
```

---
## Prometheus storage hierarchy
```
(ENV) ğŸº /Users/xsky/go/src/github.com/microyahoo/prometheus/data â˜ tree -h
.
â”œâ”€â”€ [ 192]  01DPE8T5XPQ9ZYHSNJYBJBKGR6
â”‚Â Â  â”œâ”€â”€ [  96]  chunks
â”‚Â Â  â”‚Â Â  â””â”€â”€ [7.1K]  000001
â”‚Â Â  â”œâ”€â”€ [ 22K]  index
â”‚Â Â  â”œâ”€â”€ [ 272]  meta.json
â”‚Â Â  â””â”€â”€ [   9]  tombstones
â”œâ”€â”€ [   0]  lock
â”œâ”€â”€ [ 20K]  queries.active
â””â”€â”€ [ 256]  wal
    â”œâ”€â”€ [   0]  00000050
    â”œâ”€â”€ [   0]  00000051
    â”œâ”€â”€ [   0]  00000052
    â”œâ”€â”€ [   0]  00000053
    â”œâ”€â”€ [ 10K]  00000054
    â””â”€â”€ [  96]  checkpoint.000049
        â””â”€â”€ [ 32K]  00000000

4 directories, 12 files
```
ä»ä¸Šé¢ç›®å½•ç»“æ„å¯ä»¥çœ‹å‡ºwalä¸»è¦åŒ…å«segmentæ–‡ä»¶ï¼Œcheckpointç›®å½•ã€‚
```
// WAL is a write ahead log that stores records in segment files.
// It must be read from start to end once before logging new data.
// If an error occurs during read, the repair procedure must be called
// before it's safe to do further writes.
//
// Segments are written to in pages of 32KB, with records possibly split
// across page boundaries.
// Records are never split across segments to allow full segments to be
// safely truncated. It also ensures that torn writes never corrupt records
// beyond the most recent segment.
type WAL struct {
    dir         string
    logger      log.Logger
    segmentSize int
    mtx         sync.RWMutex
    segment     *Segment // Active segment.
    donePages   int      // Pages written to the segment.
    page        *page    // Active page.
    stopc       chan chan struct{}
    actorc      chan func()
    closed      bool // To allow calling Close() more than once without blocking.
    compress    bool
    snappyBuf   []byte

    fsyncDuration   prometheus.Summary
    pageFlushes     prometheus.Counter
    pageCompletions prometheus.Counter
    truncateFail    prometheus.Counter
    truncateTotal   prometheus.Counter
    currentSegment  prometheus.Gauge
}
```
```
// Segment represents a segment file.
type Segment struct {
    *os.File
    dir string
    i   int
}
```

---
## Create Segment
åˆ›å»º`segment`ä¸»è¦æ˜¯é€šè¿‡`New`æ–¹æ³•æˆ–è€…`NewSize`æ–¹æ³•ã€‚å…¶ä¸­`NewSize`å¯ä»¥æŒ‡å®šsegmentçš„å¤§å°ï¼Œ`New`æ–¹æ³•ä¼ å…¥çš„æ˜¯é»˜è®¤çš„segmentå¤§å°ï¼Œå³128Mã€‚åŠ è½½DBæ—¶å¦‚æœWAL enabledçš„è¯ï¼Œåˆ™ä¼šè°ƒç”¨`NewSize`åˆ›å»ºæ–°çš„segmentï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚ä¸‹é¢å¯¹`NewSize`è¿›è¡Œå±•å¼€ã€‚
```
wlog, err = wal.NewSize(l, r, filepath.Join(dir, "wal"), segmentSize, opts.WALCompression)
```
- é¦–å…ˆåˆ¤æ–­æ®µå¤§å°æ˜¯å¦æ˜¯`page`çš„æ•´æ•°å€ã€‚
- å¦‚æœ`wal`ç›®å½•ä¸å­˜åœ¨çš„è¯åˆ™åˆ›å»º`wal`ç›®å½•ã€‚
- åˆ›å»ºWALæ•°æ®ç»“æ„ã€‚å› ä¸ºWALæ˜¯ä¸`active segment`å…³è”çš„ï¼Œæ‰€ä»¥WAL `segmentSize`å³ä¸ºæŒ‡å®šçš„segmentSizeã€‚
- æŸ¥æ‰¾ç›®å‰WALä¸­æ‰€æœ‰çš„segmentè®°å½•ã€‚å› ä¸ºsegmentæ˜¯æŒ‰ç…§æ•°å­—å‘½åå¹¶é€’å¢çš„ï¼Œæ‰€ä»¥å…¶åå­—å³ä¸ºç´¢å¼•ï¼Œå…¶å†…éƒ¨è¡¨è¿°ä¸º`segmentRef`ï¼Œnameä¸ºå…¶æ–‡ä»¶åï¼Œå³å‰ç¼€ä¸º0å¡«å……çš„å…«ä½æ•´å½¢è¡¨ç¤ºï¼Œindexå³ä¸ºå…¶æ•´å½¢è¡¨ç¤ºã€‚
```
type segmentRef struct {
    name  string
    index int
}
```
- ä¸Šé¢æ­¥éª¤è·å–åˆ°last segmentä¹‹åï¼Œä¸‹ä¸€ä¸ªè¦å†™å…¥çš„segment indexå³ä¸º`last+1`ï¼Œåˆ›å»ºæ–°çš„segmentã€‚
- å°†æ–°åˆ›å»ºçš„segmentè®¾ç½®ä¸ºWALçš„active segmentï¼ŒåŒæ—¶æ ¹æ®segmentæ–‡ä»¶å¤§å°è®¾ç½®WAL `donePages`ï¼Œå°†WAL `currentSegment`è®¾ç½®ä¸ºæ–°åˆ›å»ºçš„segmentçš„indexã€‚
- å¯åŠ¨æ–°çš„goroutineæ‰§è¡Œ`actorc`é€šé“å‘é€è¿‡æ¥çš„funcã€‚

---
## WAL Repair
> Repair attempts to repair the WAL based on the error.
It discards all data after the corruption.

éœ€è¦æ³¨æ„çš„æ˜¯`Repair`ä»…èƒ½ä¿®å¤`CorruptionErr`ã€‚`CorruptionErr`ä¸­æŒ‡å®šäº†ç›®å½•ï¼Œæ®µï¼Œåç§»é‡ä»¥åŠå…·ä½“çš„é”™è¯¯ä¿¡æ¯ã€‚
```
// CorruptionErr is an error that's returned when corruption is encountered.
type CorruptionErr struct {
    Dir     string
    Segment int
    Offset  int64
    Err     error
}
```
- é¦–å…ˆè·å–walç›®å½•ä¸­æ‰€æœ‰çš„segmentsã€‚
- **åˆ é™¤**`CorruptionErr.Segment`ç´¢å¼•ä¹‹åçš„æ‰€æœ‰çš„segmentsã€‚
- å…³é—­WALçš„`active segment`ã€‚
- å°†`CorruptionErr.Segment`ç´¢å¼•çš„segmentåŠ ä¸Š`.repair`åç¼€å¹¶é‡å‘½åã€‚
- åˆ›å»ºä¸€ä¸ªæ–°çš„segmentæ–‡ä»¶ï¼Œå…¶indexä¸º`CorruptionErr.Segment`ï¼Œå³Corruption segmenté‡å‘½åä¹‹åé‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„segmentæ–‡ä»¶ï¼Œå¹¶å°†WALçš„active segmentæŒ‡å‘æ–°åˆ›å»ºçš„segmentã€‚
- å°†Corruption segmentä¸­çš„æ•°æ®è¯»åˆ°æ–°åˆ›å»ºçš„segmentæ–‡ä»¶ä¸­ï¼Œè¯»åˆ°`CorruptionErr.Offset`ä¸ºæ­¢ã€‚

### WAL Reader
```
// Reader reads WAL records from an io.Reader.
type Reader struct {
    rdr       io.Reader
    err       error
    rec       []byte
    snappyBuf []byte
    buf       [pageSize]byte
    total     int64   // Total bytes processed.
    curRecTyp recType // Used for checking that the last record is not torn.
}
```
å…¶ä¸­Readerä»rdrä¸­è¯»å–recordsï¼Œç›¸å½“äºæŠŠio.Readeråšäº†ä¸€å±‚åŒ…è£…ï¼›bufä¸ºå¤§å°ä¸ºpageSizeçš„å­—èŠ‚æ•°ç»„ã€‚

```
+--------------------------------------------------+
|                     Reader.buf                   |
+-----------------------------------+--------------+
|               hdr                 |     buf      |
+-----------+----------+------------+--------------+
| type <1b> | len <2b> | CRC32 <4b> | data <bytes> |
+-----------+----------+------------+--------------+

```

the record fragment is encoded as:

```
+-----------+----------+------------+--------------+
| type <1b> | len <2b> | CRC32 <4b> | data <bytes> |
+-----------+----------+------------+--------------+
```

The type flag has the following states:

* `0`: rest of page will be empty
* `1`: a full record encoded in a single fragment
* `2`: first fragment of a record
* `3`: middle fragment of a record
* `4`: final fragment of a record

å…¶ä¸­typeå ç”¨ä¸€ä¸ªbyteï¼Œç”±äºtype flagåªæœ‰äº”ç§çŠ¶æ€ï¼Œ3 bitså°±å¯ä»¥è¡¨ç¤ºäº†ã€‚å‰4ä¸ª bitæœªåˆ†é…ï¼Œç¬¬5ä¸ªbitè¡¨ç¤ºæ˜¯å¦`å‹ç¼©`ï¼Œæœ€åä¸‰ä¸ªbitè¡¨ç¤º`record type`ã€‚
```
+--------------------+-------------------------------+------------------------+
| 4 bits unallocated | 1 bit snappy compression flag |   3 bit record type    |
+--------------------+-------------------------------+------------------------+
```

```
// Next advances the reader to the next records and returns true if it exists.
// It must not be called again after it returned false.
func (r *Reader) Next() bool {
    err := r.next()
    if errors.Cause(err) == io.EOF {
        // The last WAL segment record shouldn't be torn(should be full or last).
        // The last record would be torn after a crash just before
        // the last record part could be persisted to disk.
        if r.curRecTyp == recFirst || r.curRecTyp == recMiddle {
            r.err = errors.New("last record is torn")
        }
        return false
    }
    r.err = err
    return r.err == nil
}

func (r *Reader) next() (err error) {
    // We have to use r.buf since allocating byte arrays here fails escape
    // analysis and ends up on the heap, even though it seemingly should not.
    // å‰é¢7ä¸ªbyteä»£è¡¨headerï¼Œåé¢çš„ä¸ºdata
    hdr := r.buf[:recordHeaderSize]
    buf := r.buf[recordHeaderSize:]

    r.rec = r.rec[:0]
    r.snappyBuf = r.snappyBuf[:0]

    i := 0
    for {
        // é¦–å…ˆä»rdrä¸­è¯»å–ä¸€ä¸ªå­—èŠ‚
        if _, err = io.ReadFull(r.rdr, hdr[:1]); err != nil {
            return errors.Wrap(err, "read first header byte")
        }
        r.total++
        // è·å–record typeï¼Œå¹¶åˆ¤æ–­æ˜¯å¦å‹ç¼©
        r.curRecTyp = recTypeFromHeader(hdr[0])
        compressed := hdr[0]&snappyMask != 0

        // Gobble up zero bytes.
        // å¦‚æœrecord typeä¸ºrecPageTermï¼Œä»£è¡¨åé¢pageå‰©ä½™æ•°æ®å…¨éƒ¨ä¸º0å¡«å……ã€‚å³ç¬¬ä¸€ä¸ªbyteä¸ºtypeï¼Œåé¢å…¨æ˜¯0ã€‚
        if r.curRecTyp == recPageTerm {
            // recPageTerm is a single byte that indicates the rest of the page is padded.
            // If it's the first byte in a page, buf is too small and
            // needs to be resized to fit pageSize-1 bytes.
            buf = r.buf[1:]

            // We are pedantic and check whether the zeros are actually up
            // to a page boundary.
            // It's not strictly necessary but may catch sketchy state early.
            k := pageSize - (r.total % pageSize)
            if k == pageSize {
                continue // Initial 0 byte was last page byte.
            }
            n, err := io.ReadFull(r.rdr, buf[:k])
            if err != nil {
                return errors.Wrap(err, "read remaining zeros")
            }
            r.total += int64(n)

            for _, c := range buf[:k] {
                if c != 0 {
                    return errors.New("unexpected non-zero byte in padded page")
                }
            }
            continue
        }
        // è¯»å–å‰©ä½™çš„6ä¸ªbyteï¼Œåˆ†åˆ«ä»£è¡¨lengthå’Œcrc
        n, err := io.ReadFull(r.rdr, hdr[1:])
        if err != nil {
            return errors.Wrap(err, "read remaining header")
        }
        r.total += int64(n)

        var (
            length = binary.BigEndian.Uint16(hdr[1:])
            crc    = binary.BigEndian.Uint32(hdr[3:])
        )

        if length > pageSize-recordHeaderSize {
            return errors.Errorf("invalid record size %d", length)
        }
        // è¯»å–é•¿åº¦ä¸ºlengthçš„æ•°æ®ï¼Œå¹¶è®¡ç®—å…¶crcå€¼æ˜¯å¦ä¸headerä¸­çš„crcç›¸ç­‰ã€‚
        n, err = io.ReadFull(r.rdr, buf[:length])
        if err != nil {
            return err
        }
        r.total += int64(n)

        if n != int(length) {
            return errors.Errorf("invalid size: expected %d, got %d", length, n)
        }
        if c := crc32.Checksum(buf[:length], castagnoliTable); c != crc {
            return errors.Errorf("unexpected checksum %x, expected %x", c, crc)
        }
        
        // å¦‚æœä¸ºå‹ç¼©æ•°æ®ï¼Œåˆ™å°†å…¶å­˜æ”¾åœ¨snappyBufä¸­ï¼Œåé¢è¯»å–å®Œæˆåè¿›è¡Œdecodeã€‚
        if compressed {
            r.snappyBuf = append(r.snappyBuf, buf[:length]...)
        } else {
            r.rec = append(r.rec, buf[:length]...)
        }

        if err := validateRecord(r.curRecTyp, i); err != nil {
            return err
        }
        if r.curRecTyp == recLast || r.curRecTyp == recFull {
            if compressed && len(r.snappyBuf) > 0 {
                // The snappy library uses `len` to calculate if we need a new buffer.
                // In order to allocate as few buffers as possible make the length
                // equal to the capacity.
                // å°†å‹ç¼©çš„æ•°æ®è¿›è¡Œè§£ç ã€‚
                r.rec = r.rec[:cap(r.rec)]
                r.rec, err = snappy.Decode(r.rec, r.snappyBuf)
                return err
            }
            return nil
        }
        // Only increment i for non-zero records since we use it
        // to determine valid content record sequences.
        i++
    }
}
```
`Next`æ–¹æ³•ä»`rdr`ä¸­è¯»å–recordï¼Œå¦‚æœå­˜åœ¨åˆ™è¿”å›trueã€‚æ¯æ¬¡è¯»å–ä¸€ä¸ª`page`å¤§å°çš„æ•°æ®ï¼Œç›´åˆ°è¯»å–å®Œæ•´çš„`record`ï¼Œå¦‚æœæ•°æ®è¢«å‹ç¼©ï¼Œåˆ™éœ€è¦`decode`ï¼Œæœ€åçš„recordå­˜å‚¨åœ¨`Reader.rec`å­—æ®µä¸­ã€‚

#### é—®é¢˜ç‚¹
1. ä¸ºä»€ä¹ˆéœ€è¦`recPageTerm`ç±»å‹ï¼Œè¿™æ ·æ˜¯ä¸æ˜¯æµªè´¹äº†ä¸€æ•´ä¸ªpageå¤§å°çš„ç©ºé—´ï¼Ÿ
2. `record`ä»£è¡¨ä»€ä¹ˆï¼Ÿ

---
## References
- [WAL disk format](https://github.com/prometheus/prometheus/blob/master/tsdb/docs/format/wal.md)
- [prometheus tsdbéƒ¨åˆ†æºç é˜…è¯»ä¹‹wal.LogSeries](https://www.jianshu.com/p/e0144be9692a)
- [è¯¦è§£varintç¼–ç åŸç†](https://segmentfault.com/a/1190000020500985?utm_source=tag-newest)
- [RocksDB WAL file format](https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log-File-Format)