# Prometheus WALæºç é˜…è¯»

---
## æ¦‚è¿°
WAL(Write-ahead logging, é¢„å†™æ—¥å¿—)æ˜¯å…³ç³»å‹æ•°æ®åº“ä¸­åˆ©ç”¨æ—¥å¿—æ¥å®ç°äº‹åŠ¡æ€§å’ŒæŒä¹…æ€§çš„ä¸€ç§æŠ€æœ¯ï¼Œå³åœ¨æŸä¸ªæ“ä½œä¹‹å‰å…ˆå°†è¿™ä¸ªäº‹æƒ…è®°å½•ä¸‹æ¥ï¼Œä»¥ä¾¿ä¹‹åå¯¹æ•°æ®è¿›è¡Œå›æ»šï¼Œé‡è¯•ç­‰æ“ä½œä¿è¯æ•°æ®çš„å¯é æ€§ã€‚

Prometheusä¸ºäº†é˜²æ­¢ä¸¢å¤±æš‚å­˜åœ¨å†…å­˜ä¸­çš„è¿˜æœªè¢«å†™å…¥ç£ç›˜çš„ç›‘æ§æ•°æ®ï¼Œå¼•å…¥äº†WALæœºåˆ¶ã€‚WALè¢«åˆ†å‰²æˆé»˜è®¤å¤§å°ä¸º128Mçš„æ–‡ä»¶æ®µï¼ˆsegmentï¼‰ï¼Œä¹‹å‰ç‰ˆæœ¬é»˜è®¤å¤§å°æ˜¯256Mï¼Œæ–‡ä»¶æ®µä»¥æ•°å­—å‘½åï¼Œé•¿åº¦ä¸º8ä½çš„æ•´å½¢ã€‚WALçš„å†™å…¥å•ä½æ˜¯é¡µï¼ˆpageï¼‰ï¼Œæ¯é¡µçš„å¤§å°ä¸º32KBï¼Œæ‰€ä»¥æ¯ä¸ªæ®µå¤§å°å¿…é¡»æ˜¯é¡µçš„å¤§å°çš„æ•´æ•°å€ã€‚æ¯ä¸ªæ–‡ä»¶æ®µéƒ½æœ‰ä¸€ä¸ªâ€œ==å·²ä½¿ç”¨çš„é¡µï¼Ÿ==â€å±æ€§æ¥æ ‡è¯†åœ¨è¯¥æ®µä¸­å·²ç»åˆ†é…çš„é¡µæ•°ç›®ï¼Œå¦‚æœWALä¸€æ¬¡æ€§å†™å…¥çš„é¡µæ•°è¶…è¿‡ä¸€ä¸ªæ®µçš„ç©ºé—²é¡µæ•°ï¼Œå°±ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„æ–‡ä»¶æ®µæ¥ä¿å­˜è¿™äº›é¡µï¼Œä»è€Œç¡®ä¿ä¸€æ¬¡æ€§å†™å…¥çš„é¡µ**ä¸ä¼šè·¨æ®µå­˜å‚¨**ã€‚
```
const (
     DefaultSegmentSize = 128 * 1024 * 1024 // 128 MB
     pageSize           = 32 * 1024         // 32KB
     recordHeaderSize   = 7
)
```

æœ¬æ–‡æ˜¯åœ¨[prometheus tsdbéƒ¨åˆ†æºç é˜…è¯»ä¹‹wal.LogSeries](https://www.jianshu.com/p/e0144be9692a)åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•ï¼Œç”±äº`tsdb/wal.go`æ–‡ä»¶ä¸­å®šä¹‰çš„WALæ¥å£ä»¥åŠç›¸å…³æ–¹æ³•å·²ç»deprecatedï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚å› æ­¤æœ¬æ–‡é’ˆå¯¹`tsdb/wal/wal.go`æ–‡ä»¶è¿›è¡Œåˆ†æã€‚

```
// WAL is a write ahead log that can log new series labels and samples.
// It must be completely read before new entries are logged.
//
// DEPRECATED: use wal pkg combined with the record codex instead.
type WAL interface {
    Reader() WALReader
    LogSeries([]RefSeries) error
    LogSamples([]RefSample) error
    LogDeletes([]Stone) error
    Truncate(mint int64, keep func(uint64) bool) error
    Close() error
}
```

---
## Prometheus storage hierarchy
```
(ENV) ğŸº /Users/xsky/go/src/github.com/microyahoo/prometheus/data â˜ tree -h
.
â”œâ”€â”€ [ 192]  01DPE8T5XPQ9ZYHSNJYBJBKGR6
â”‚Â Â  â”œâ”€â”€ [  96]  chunks
â”‚Â Â  â”‚Â Â  â””â”€â”€ [7.1K]  000001
â”‚Â Â  â”œâ”€â”€ [ 22K]  index
â”‚Â Â  â”œâ”€â”€ [ 272]  meta.json
â”‚Â Â  â””â”€â”€ [   9]  tombstones
â”œâ”€â”€ [   0]  lock
â”œâ”€â”€ [ 20K]  queries.active
â””â”€â”€ [ 256]  wal
    â”œâ”€â”€ [   0]  00000050
    â”œâ”€â”€ [   0]  00000051
    â”œâ”€â”€ [   0]  00000052
    â”œâ”€â”€ [   0]  00000053
    â”œâ”€â”€ [ 10K]  00000054
    â””â”€â”€ [  96]  checkpoint.000049
        â””â”€â”€ [ 32K]  00000000

4 directories, 12 files
```
ä»ä¸Šé¢ç›®å½•ç»“æ„å¯ä»¥çœ‹å‡ºwalä¸»è¦åŒ…å«segmentæ–‡ä»¶ï¼Œcheckpointç›®å½•ã€‚
```
// WAL is a write ahead log that stores records in segment files.
// It must be read from start to end once before logging new data.
// If an error occurs during read, the repair procedure must be called
// before it's safe to do further writes.
//
// Segments are written to in pages of 32KB, with records possibly split
// across page boundaries.
// Records are never split across segments to allow full segments to be
// safely truncated. It also ensures that torn writes never corrupt records
// beyond the most recent segment.
type WAL struct {
    dir         string
    logger      log.Logger
    segmentSize int
    mtx         sync.RWMutex
    segment     *Segment // Active segment.
    donePages   int      // Pages written to the segment.
    page        *page    // Active page.
    stopc       chan chan struct{}
    actorc      chan func()
    closed      bool // To allow calling Close() more than once without blocking.
    compress    bool
    snappyBuf   []byte

    fsyncDuration   prometheus.Summary
    pageFlushes     prometheus.Counter
    pageCompletions prometheus.Counter
    truncateFail    prometheus.Counter
    truncateTotal   prometheus.Counter
    currentSegment  prometheus.Gauge
}
```
```
// Segment represents a segment file.
type Segment struct {
    *os.File
    dir string
    i   int
}
```
![](https://note.youdao.com/yws/api/personal/file/WEBb9810f4ea734eae8aec71710c79e3329?method=getImage&version=12759&cstk=-lHXuqC6)

---
## Create Segment
åˆ›å»º`segment`ä¸»è¦æ˜¯é€šè¿‡`New`æ–¹æ³•æˆ–è€…`NewSize`æ–¹æ³•ã€‚å…¶ä¸­`NewSize`å¯ä»¥æŒ‡å®šsegmentçš„å¤§å°ï¼Œ`New`æ–¹æ³•ä¼ å…¥çš„æ˜¯é»˜è®¤çš„segmentå¤§å°ï¼Œå³128Mã€‚åŠ è½½DBæ—¶å¦‚æœWAL enabledçš„è¯ï¼Œåˆ™ä¼šè°ƒç”¨`NewSize`åˆ›å»ºæ–°çš„segmentï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚ä¸‹é¢å¯¹`NewSize`è¿›è¡Œå±•å¼€ã€‚
```
wlog, err = wal.NewSize(l, r, filepath.Join(dir, "wal"), segmentSize, opts.WALCompression)
```
- é¦–å…ˆåˆ¤æ–­æ®µå¤§å°æ˜¯å¦æ˜¯`page`çš„æ•´æ•°å€ã€‚
- å¦‚æœ`wal`ç›®å½•ä¸å­˜åœ¨çš„è¯åˆ™åˆ›å»º`wal`ç›®å½•ã€‚
- åˆ›å»ºWALæ•°æ®ç»“æ„ã€‚å› ä¸ºWALæ˜¯ä¸`active segment`å…³è”çš„ï¼Œæ‰€ä»¥WAL `segmentSize`å³ä¸ºæŒ‡å®šçš„segmentSizeã€‚
- æŸ¥æ‰¾ç›®å‰WALä¸­æ‰€æœ‰çš„segmentè®°å½•ã€‚å› ä¸ºsegmentæ˜¯æŒ‰ç…§æ•°å­—å‘½åå¹¶é€’å¢çš„ï¼Œæ‰€ä»¥å…¶åå­—å³ä¸ºç´¢å¼•ï¼Œå…¶å†…éƒ¨è¡¨è¿°ä¸º`segmentRef`ï¼Œnameä¸ºå…¶æ–‡ä»¶åï¼Œå³å‰ç¼€ä¸º0å¡«å……çš„å…«ä½æ•´å½¢è¡¨ç¤ºï¼Œindexå³ä¸ºå…¶æ•´å½¢è¡¨ç¤ºã€‚
```
type segmentRef struct {
    name  string
    index int
}
```
- ä¸Šé¢æ­¥éª¤è·å–åˆ°last segmentä¹‹åï¼Œä¸‹ä¸€ä¸ªè¦å†™å…¥çš„segment indexå³ä¸º`last+1`ï¼Œåˆ›å»ºæ–°çš„segmentã€‚
- å°†æ–°åˆ›å»ºçš„segmentè®¾ç½®ä¸ºWALçš„active segmentï¼ŒåŒæ—¶æ ¹æ®segmentæ–‡ä»¶å¤§å°è®¾ç½®WAL `donePages`ï¼Œå°†WAL `currentSegment`è®¾ç½®ä¸ºæ–°åˆ›å»ºçš„segmentçš„indexã€‚
- å¯åŠ¨æ–°çš„goroutineæ‰§è¡Œ`actorc`é€šé“å‘é€è¿‡æ¥çš„funcã€‚ä¸»è¦ç”¨äºæ‰§è¡Œæ¯”è¾ƒè€—æ—¶çš„æ“ä½œï¼Œä¾‹å¦‚å°†segmentä¸­çš„æ•°æ®`fsync`åˆ°diskä¸­ã€‚

---
## WAL Repair
> Repair attempts to repair the WAL based on the error.
It discards all data after the corruption.

éœ€è¦æ³¨æ„çš„æ˜¯`Repair`ä»…èƒ½ä¿®å¤`CorruptionErr`ã€‚`CorruptionErr`ä¸­æŒ‡å®šäº†ç›®å½•ï¼Œæ®µï¼Œåç§»é‡ä»¥åŠå…·ä½“çš„é”™è¯¯ä¿¡æ¯ã€‚
```
// CorruptionErr is an error that's returned when corruption is encountered.
type CorruptionErr struct {
    Dir     string
    Segment int
    Offset  int64
    Err     error
}
```
- é¦–å…ˆè·å–walç›®å½•ä¸­æ‰€æœ‰çš„segmentsã€‚
- **åˆ é™¤**`CorruptionErr.Segment`ç´¢å¼•ä¹‹åçš„æ‰€æœ‰çš„segmentsã€‚
- å…³é—­WALçš„`active segment`ã€‚
- å°†`CorruptionErr.Segment`ç´¢å¼•çš„segmentåŠ ä¸Š`.repair`åç¼€å¹¶é‡å‘½åã€‚
- åˆ›å»ºä¸€ä¸ªæ–°çš„segmentæ–‡ä»¶ï¼Œå…¶indexä¸º`CorruptionErr.Segment`ï¼Œå³Corruption segmenté‡å‘½åä¹‹åé‡æ–°åˆ›å»ºä¸€ä¸ªæ–°çš„segmentæ–‡ä»¶ï¼Œå¹¶å°†WALçš„active segmentæŒ‡å‘æ–°åˆ›å»ºçš„segmentã€‚
- å°†Corruption segmentä¸­çš„æ•°æ®è¯»åˆ°æ–°åˆ›å»ºçš„segmentæ–‡ä»¶ä¸­ï¼Œè¯»åˆ°`CorruptionErr.Offset`ä¸ºæ­¢ã€‚
    - éå†è¯»å–corrupted segmentä¸­çš„recordsï¼Œå°†å…¶å†™å…¥new segmentä¸­ã€‚
- å°†active pageåˆ·å…¥fileã€‚
- å…³é—­corrupted segmentæ–‡ä»¶ï¼Œå¹¶åˆ é™¤ã€‚
- åˆ›å»ºä¸€ä¸ªæ–°çš„segmentæ–‡ä»¶ï¼Œå…¶indexä¸º`CorruptionErr.Segment`çš„index+1ï¼Œå¹¶å°†active segmentæŒ‡å‘æ–°åˆ›å»ºçš„segmentã€‚

ä¸‹é¢æˆªå–`tsdb/wal/wal.go`æ–‡ä»¶ä¸­çš„éƒ¨åˆ†Repairçš„ä»£ç è¿›è¡Œåˆ†æã€‚
```
    // æ‰“å¼€corrupted segmentæ–‡ä»¶å¹¶è¯»å–å…¶ä¸­çš„recordsã€‚
    r := NewReader(bufio.NewReader(f))

    // ä¸‹é¢WAL Readeréƒ¨åˆ†æœ‰è¯¦ç»†è§£é‡Š
    for r.Next() {
        // Add records only up to the where the error was.
        // è¯»å–åˆ°å‡ºé”™çš„åœ°æ–¹ä¸ºæ­¢ã€‚
        if r.Offset() >= cerr.Offset {
            break
        }
        // ä¸‹é¢ç€é‡ä»‹ç»æ­¤æ–¹æ³•
        if err := w.Log(r.Record()); err != nil {
            return errors.Wrap(err, "insert record")
        }
    }
    // We expect an error here from r.Err(), so nothing to handle.

    // We need to pad to the end of the last page in the repaired segment
    if err := w.flushPage(true); err != nil {
        return errors.Wrap(err, "flush page in repair")
    }

    // We explicitly close even when there is a defer for Windows to be
    // able to delete it. The defer is in place to close it in-case there
    // are errors above.
    if err := f.Close(); err != nil {
        return errors.Wrap(err, "close corrupted file")
    }
    // åˆ é™¤.repairæ–‡ä»¶
    if err := os.Remove(tmpfn); err != nil {
        return errors.Wrap(err, "delete corrupted segment")
    }

    // Explicitly close the segment we just repaired to avoid issues with Windows.
    s.Close()
    
    // We always want to start writing to a new Segment rather than an existing
    // Segment, which is handled by NewSize, but earlier in Repair we're deleting
    // all segments that come after the corrupted Segment. Recreate a new Segment here.
    // åˆ›å»ºæ–°çš„segment fileï¼Œå¹¶å°†active segmentæŒ‡å‘æ­¤æ–°åˆ›å»ºçš„segment file
    s, err = CreateSegment(w.dir, cerr.Segment+1)
    if err != nil {
        return err
    }
    if err := w.setSegment(s); err != nil {
        return err
    }
    return nil
```
Repairçš„æ ¸å¿ƒå°±æ˜¯å°†corrupted segmentæ–‡ä»¶ä¸­çš„æ•°æ®å†™å…¥æ–°çš„segmentä¸­ï¼Œç„¶ååˆ é™¤corrupted segmentæ–‡ä»¶ã€‚ä¸‹é¢ç€é‡ä»‹ç»å…¶å†™å…¥è¿‡ç¨‹ï¼Œä¸»è¦æ˜¯è°ƒç”¨WALçš„`log`æ–¹æ³•ã€‚
```
// log writes rec to the log and forces a flush of the current page if:
// - the final record of a batch
// - the record is bigger than the page size
// - the current page is full.
func (w *WAL) log(rec []byte, final bool) error {
    // When the last page flush failed the page will remain full.
    // When the page is full, need to flush it before trying to add more records to it.
    // å¦‚æœWALçš„active pageå·²æ»¡ï¼Œåˆ™flushåˆ°fileï¼Œå¹¶é‡ç½®æ­¤page
    if w.page.full() {
        if err := w.flushPage(true); err != nil {
            return err
        }
    }
    // If the record is too big to fit within the active page in the current
    // segment, terminate the active segment and advance to the next one.
    // This ensures that records do not cross segment boundaries.
    left := w.page.remaining() - recordHeaderSize                                   // Free space in the active page.
    left += (pageSize - recordHeaderSize) * (w.pagesPerSegment() - w.donePages - 1) // Free pages in the active segment.

    // å¦‚æœrecordçš„é•¿åº¦å¤§äºactive segmentçš„å‰©ä½™å¯ç”¨ç©ºé—´ï¼Œåˆ™åˆ›å»ºæ–°çš„segment
    if len(rec) > left {
        // 1. å¦‚æœactive pageå·²åˆ†é…å¤§å°ä¸ä¸º0ï¼Œåˆ™flush pageåˆ°fileã€‚
        // 2. åˆ›å»ºæ–°çš„segment fileã€‚
        // 3. å°†ä¸Šä¸€ä¸ªsegment fileçš„æ•°æ®fsyncåˆ°ç£ç›˜ã€‚
        if err := w.nextSegment(); err != nil {
            return err
        }
    }

    compressed := false
    if w.compress && len(rec) > 0 {
        // The snappy library uses `len` to calculate if we need a new buffer.
        // In order to allocate as few buffers as possible make the length
        // equal to the capacity.
        // å¦‚æœWAL compress enabledï¼Œåˆ™å°†recordæ•°æ®ç¼–ç ä¸ºsnappyBufï¼Œ
        // å°†recæŒ‡å‘å‹ç¼©åçš„snappyBufæ•°æ®è®°å½•ã€‚
        w.snappyBuf = w.snappyBuf[:cap(w.snappyBuf)]
        w.snappyBuf = snappy.Encode(w.snappyBuf, rec)
        if len(w.snappyBuf) < len(rec) {
            rec = w.snappyBuf
            compressed = true
        }
    }

    // Populate as many pages as necessary to fit the record.
    // Be careful to always do one pass to ensure we write zero-length records.
    for i := 0; i == 0 || len(rec) > 0; i++ {
        p := w.page

        // Find how much of the record we can fit into the page.
        var (
            l    = min(len(rec), (pageSize-p.alloc)-recordHeaderSize)
            part = rec[:l]
            // bufæŒ‡å‘page.bufçš„offsetä¸ºpage.alloc
            buf  = p.buf[p.alloc:] 
            typ  recType
        )

        switch {
        case i == 0 && len(part) == len(rec):
            typ = recFull
        case len(part) == len(rec):
            typ = recLast
        case i == 0:
            typ = recFirst
        default:
            typ = recMiddle
        }
        if compressed {
            typ |= snappyMask
        }
        // åˆ¤æ–­recordçš„typeå’Œæ˜¯å¦compressï¼Œå¹¶å°†å…¶å†™å…¥bufçš„ç¬¬ä¸€ä¸ªå­—èŠ‚ã€‚
        // æ¥ç€å†™å…¥2å­—èŠ‚çš„é•¿åº¦ä¸ºmin(len(record), (pageSize-p.alloc)-recordHeaderSize)ï¼Œ
        // ä¹Ÿå°±æ˜¯è¯´æœ‰å¯èƒ½recordçš„é•¿åº¦å¤§äºactive pageæ‰€èƒ½åˆ†é…çš„æœ€å¤§é•¿åº¦ï¼Œ
        // è¿™æ ·recordå°±ä¼šè·¨pageï¼Œä½†æ˜¯ä¸èƒ½è·¨segmentã€‚
        // ç„¶åå†™å…¥4ä¸ªå­—èŠ‚çš„CRC
        buf[0] = byte(typ)
        crc := crc32.Checksum(part, castagnoliTable)
        binary.BigEndian.PutUint16(buf[1:], uint16(len(part)))
        binary.BigEndian.PutUint32(buf[3:], crc)

        // ç´§æ¥ç€headerå†™å…¥recordæ•°æ®è®°å½•ï¼Œå¯èƒ½æ˜¯ä¸€éƒ¨åˆ†ã€‚
        copy(buf[recordHeaderSize:], part)
        p.alloc += len(part) + recordHeaderSize

        // å¦‚æœpageå·²æ»¡ï¼Œåˆ™flushåˆ°fileä¸­ã€‚
        if w.page.full() {
            if err := w.flushPage(true); err != nil {
                return err
            }
        }
        rec = rec[l:]
    }
    
    // If it's the final record of the batch and the page is not empty, flush it.
    if final && w.page.alloc > 0 {
        if err := w.flushPage(false); err != nil {
            return err
        }
    }

    return nil
}
```

### WAL Reader
```
// Reader reads WAL records from an io.Reader.
type Reader struct {
    rdr       io.Reader
    err       error
    rec       []byte
    snappyBuf []byte
    buf       [pageSize]byte
    total     int64   // Total bytes processed.
    curRecTyp recType // Used for checking that the last record is not torn.
}
```
å…¶ä¸­Readerä»rdrä¸­è¯»å–recordsï¼Œç›¸å½“äºæŠŠio.Readeråšäº†ä¸€å±‚åŒ…è£…ï¼›bufä¸ºå¤§å°ä¸ºpageSizeçš„å­—èŠ‚æ•°ç»„ã€‚

```
+--------------------------------------------------+
|                     Reader.buf                   |
+-----------------------------------+--------------+
|               hdr                 |     buf      |
+-----------+----------+------------+--------------+
| type <1b> | len <2b> | CRC32 <4b> | data <bytes> |
+-----------+----------+------------+--------------+

```

the record fragment is encoded as:

```
+-----------+----------+------------+--------------+
| type <1b> | len <2b> | CRC32 <4b> | data <bytes> |
+-----------+----------+------------+--------------+
```

The type flag has the following states:

* `0`: rest of page will be empty
* `1`: a full record encoded in a single fragment
* `2`: first fragment of a record
* `3`: middle fragment of a record
* `4`: final fragment of a record

å…¶ä¸­typeå ç”¨ä¸€ä¸ªbyteï¼Œç”±äºtype flagåªæœ‰äº”ç§çŠ¶æ€ï¼Œ3 bitså°±å¯ä»¥è¡¨ç¤ºäº†ã€‚å‰4ä¸ª bitæœªåˆ†é…ï¼Œç¬¬5ä¸ªbitè¡¨ç¤ºæ˜¯å¦`å‹ç¼©`ï¼Œæœ€åä¸‰ä¸ªbitè¡¨ç¤º`record type`ã€‚
```
+--------------------+-------------------------------+------------------------+
| 4 bits unallocated | 1 bit snappy compression flag |   3 bit record type    |
+--------------------+-------------------------------+------------------------+
```

```
// Next advances the reader to the next records and returns true if it exists.
// It must not be called again after it returned false.
func (r *Reader) Next() bool {
    err := r.next()
    if errors.Cause(err) == io.EOF {
        // The last WAL segment record shouldn't be torn(should be full or last).
        // The last record would be torn after a crash just before
        // the last record part could be persisted to disk.
        if r.curRecTyp == recFirst || r.curRecTyp == recMiddle {
            r.err = errors.New("last record is torn")
        }
        return false
    }
    r.err = err
    return r.err == nil
}

func (r *Reader) next() (err error) {
    // We have to use r.buf since allocating byte arrays here fails escape
    // analysis and ends up on the heap, even though it seemingly should not.
    // å‰é¢7ä¸ªbyteä»£è¡¨headerï¼Œåé¢çš„ä¸ºdata
    hdr := r.buf[:recordHeaderSize]
    buf := r.buf[recordHeaderSize:]

    r.rec = r.rec[:0]
    r.snappyBuf = r.snappyBuf[:0]

    i := 0
    for {
        // é¦–å…ˆä»rdrä¸­è¯»å–ä¸€ä¸ªå­—èŠ‚
        if _, err = io.ReadFull(r.rdr, hdr[:1]); err != nil {
            return errors.Wrap(err, "read first header byte")
        }
        r.total++
        // è·å–record typeï¼Œå¹¶åˆ¤æ–­æ˜¯å¦å‹ç¼©
        r.curRecTyp = recTypeFromHeader(hdr[0])
        compressed := hdr[0]&snappyMask != 0

        // Gobble up zero bytes.
        // å¦‚æœrecord typeä¸ºrecPageTermï¼Œä»£è¡¨åé¢pageå‰©ä½™æ•°æ®å…¨éƒ¨ä¸º0å¡«å……ã€‚å³ç¬¬ä¸€ä¸ªbyteä¸ºtypeï¼Œåé¢å…¨æ˜¯0ã€‚
        if r.curRecTyp == recPageTerm {
            // recPageTerm is a single byte that indicates the rest of the page is padded.
            // If it's the first byte in a page, buf is too small and
            // needs to be resized to fit pageSize-1 bytes.
            buf = r.buf[1:]

            // We are pedantic and check whether the zeros are actually up
            // to a page boundary.
            // It's not strictly necessary but may catch sketchy state early.
            k := pageSize - (r.total % pageSize)
            if k == pageSize {
                continue // Initial 0 byte was last page byte.
            }
            n, err := io.ReadFull(r.rdr, buf[:k])
            if err != nil {
                return errors.Wrap(err, "read remaining zeros")
            }
            r.total += int64(n)

            for _, c := range buf[:k] {
                if c != 0 {
                    return errors.New("unexpected non-zero byte in padded page")
                }
            }
            continue
        }
        // è¯»å–å‰©ä½™çš„6ä¸ªbyteï¼Œåˆ†åˆ«ä»£è¡¨lengthå’Œcrc
        n, err := io.ReadFull(r.rdr, hdr[1:])
        if err != nil {
            return errors.Wrap(err, "read remaining header")
        }
        r.total += int64(n)

        var (
            length = binary.BigEndian.Uint16(hdr[1:])
            crc    = binary.BigEndian.Uint32(hdr[3:])
        )

        if length > pageSize-recordHeaderSize {
            return errors.Errorf("invalid record size %d", length)
        }
        // è¯»å–é•¿åº¦ä¸ºlengthçš„æ•°æ®ï¼Œå¹¶è®¡ç®—å…¶crcå€¼æ˜¯å¦ä¸headerä¸­çš„crcç›¸ç­‰ã€‚
        n, err = io.ReadFull(r.rdr, buf[:length])
        if err != nil {
            return err
        }
        r.total += int64(n)

        if n != int(length) {
            return errors.Errorf("invalid size: expected %d, got %d", length, n)
        }
        if c := crc32.Checksum(buf[:length], castagnoliTable); c != crc {
            return errors.Errorf("unexpected checksum %x, expected %x", c, crc)
        }
        
        // å¦‚æœä¸ºå‹ç¼©æ•°æ®ï¼Œåˆ™å°†å…¶å­˜æ”¾åœ¨snappyBufä¸­ï¼Œåé¢è¯»å–å®Œæˆåè¿›è¡Œdecodeã€‚
        if compressed {
            r.snappyBuf = append(r.snappyBuf, buf[:length]...)
        } else {
            r.rec = append(r.rec, buf[:length]...)
        }

        if err := validateRecord(r.curRecTyp, i); err != nil {
            return err
        }
        if r.curRecTyp == recLast || r.curRecTyp == recFull {
            if compressed && len(r.snappyBuf) > 0 {
                // The snappy library uses `len` to calculate if we need a new buffer.
                // In order to allocate as few buffers as possible make the length
                // equal to the capacity.
                // å°†å‹ç¼©çš„æ•°æ®è¿›è¡Œè§£ç ã€‚
                r.rec = r.rec[:cap(r.rec)]
                r.rec, err = snappy.Decode(r.rec, r.snappyBuf)
                return err
            }
            return nil
        }
        // Only increment i for non-zero records since we use it
        // to determine valid content record sequences.
        i++
    }
}
```
`Next`æ–¹æ³•ä»`rdr`ä¸­è¯»å–recordï¼Œå¦‚æœå­˜åœ¨åˆ™è¿”å›trueã€‚æ¯æ¬¡æœ€å¤šè¯»å–`pageSize-recordHeaderSize`å¤§å°çš„æ•°æ®ï¼Œç›´åˆ°è¯»å–å®Œæ•´çš„`record`ï¼Œå¦‚æœæ•°æ®è¢«å‹ç¼©ï¼Œåˆ™éœ€è¦`decode`ï¼Œæœ€åçš„recordå­˜å‚¨åœ¨`Reader.rec`å­—æ®µä¸­ã€‚

#### é—®é¢˜ç‚¹
1. ä¸ºä»€ä¹ˆéœ€è¦`recPageTerm`ç±»å‹ï¼Œè¿™æ ·æ˜¯ä¸æ˜¯æµªè´¹äº†ä¸€æ•´ä¸ªpageå¤§å°çš„ç©ºé—´ï¼Ÿ
2. `record`ä»£è¡¨ä»€ä¹ˆï¼Ÿ
3. ä¸ºä»€ä¹ˆ`length`ä¸èƒ½å¤§äº`pageSize-recordHeaderSize`ï¼Ÿ
4. recordçš„å¤§å°ä¼šå¤§äºsegmentå—ï¼Ÿ

---
## References
- [WAL disk format](https://github.com/prometheus/prometheus/blob/master/tsdb/docs/format/wal.md)
- [prometheus tsdbéƒ¨åˆ†æºç é˜…è¯»ä¹‹wal.LogSeries](https://www.jianshu.com/p/e0144be9692a)
- [è¯¦è§£varintç¼–ç åŸç†](https://segmentfault.com/a/1190000020500985?utm_source=tag-newest)
- [RocksDB WAL file format](https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log-File-Format)